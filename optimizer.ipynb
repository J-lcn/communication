{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af98799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from line_search import armijo\n",
    "from line_search import exact\n",
    "from line_search import constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d11529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OptimizerFactory:\n",
    "    def __init__(self, model, eps):\n",
    "        self.model, self.eps = model, eps\n",
    "        self.method_dict = {'Gradient': Gradient, 'Newton': Newton , 'ModifiedNewton': ModifiedNetwon,'BFGS':BFGS, 'DFP': DFP}\n",
    "    \n",
    "    def create_method(self, method):\n",
    "        return self.method_dict.get(method)(self.model, self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1f39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, model, eps) -> None:\n",
    "        self.m, self.eps = model, eps\n",
    "        self.trace_obj, self.trace_x = [], []\n",
    "        self.trace_step, self.trace_d = [], []\n",
    "    \n",
    "    def set_init(self, lb = 0, ub = 1)-> None:\n",
    "        assert(lb <= ub), print(\"ub is larger than lb\")\n",
    "        self.x = (ub - lb) + np.random.rand(self.m.dim) + lb * np.ones(self.m.dim)\n",
    "    \n",
    "    def first_order(self):\n",
    "        self.grad, self.obj_values = self.m.diff_eval(self.x), self.m.obj_fun_eval(self.x)\n",
    "        return self.grad, self.obj_values\n",
    "    \n",
    "    def second_order(self):\n",
    "        self.hessian = self.m.diff_second_eval(self.x)\n",
    "        return self.hessian\n",
    "    \n",
    "    def get_step(self):\n",
    "        # self.step = armijo(self.x, self.d, self.grad, self.obj_values, self.m.obj_fun_eval)\n",
    "        self.step = exact(self.x, self.d, self.m.obj_fun_eval)\n",
    "\n",
    "    def moniter(self, iter_time):\n",
    "        self.trace_obj.append(self.obj_values)\n",
    "        self.trace_x.append(self.x)\n",
    "        self.trace_d.append(self.d)\n",
    "        self.trace_step.append(self.step)\n",
    "        #if iter_time % 20 == 19:\n",
    "            #print(\"iterations {} - objective function: {} - grad norm: {}\".format(iter_time, self.obj_values, np.linalg.norm(self.grad)))\n",
    "    \n",
    "    def is_stop(self):\n",
    "        if np.linalg.norm(self.grad, 1.0) <= self.eps:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def update(self):\n",
    "        assert(self.step != False), print(\"objective function is not decreased\")\n",
    "        self.x += self.step * self.d\n",
    "    \n",
    "    def save(self):\n",
    "        self.file_route = \"./results//\"\n",
    "        pd.DataFrame(self.trace_obj).to_csv(self.file_route + \"trace_obj.csv\")\n",
    "        pd.DataFrame(self.trace_x).to_csv(self.file_route + \"trace_x.csv\")\n",
    "        pd.DataFrame(self.trace_d).to_csv(self.file_route + \"trace_d.csv\")\n",
    "        pd.DataFrame(self.trace_step).to_csv(self.file_route + \"trace_step.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84ccaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Newton(Optimizer):\n",
    "    def __init__(self, model, eps) -> None:\n",
    "        super().__init__(model, eps)\n",
    "        \n",
    "        \n",
    "    def get_step(self):\n",
    "        # self.step = armijo(self.x, self.d, self.grad, self.obj_values, self.m.obj_fun_eval)\n",
    "        self.step = 1\n",
    "    \n",
    "    def search_direction(self, iter_time):\n",
    "        self.grad, self.obj_values = self.first_order()\n",
    "        self.hessian = self.second_order()\n",
    "        self.d = -1.0 * np.dot(np.linalg.inv(self.hessian), self.grad)\n",
    "        self.iter_time=iter_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f51ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedNetwon(Optimizer):\n",
    "    def __init__(self, model, eps) -> None:\n",
    "        super().__init__(model, eps)\n",
    "    \n",
    "    def search_direction(self, miu,iter_time):\n",
    "        self.grad, self.obj_values = self.first_order()\n",
    "        self.hessian = self.second_order()\n",
    "        self.d = -1.0 * np.dot(np.linalg.inv(self.hessian + miu*np.eye(self.hessian.shape[0])), self.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dacdd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gradient(Optimizer):\n",
    "    def __init__(self, model, eps) -> None:\n",
    "        super().__init__(model, eps)\n",
    "    \n",
    "    def search_direction(self):\n",
    "        self.grad, self.obj_values = self.first_order()\n",
    "        self.d = -1.0 * self.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808756da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BFGS(Optimizer):\n",
    "    def __init__(self, model, eps) -> None:\n",
    "        super().__init__(model, eps)\n",
    "        self.h = self.__generate_approx_hessian()\n",
    "    \n",
    "    def __generate_approx_hessian(self):\n",
    "        return np.eye(self.m.dim)\n",
    "    \n",
    "    def __approx_hessian(self):\n",
    "        self.s, self.y = self.x - self.x_hat, self.grad - self.grad_hat\n",
    "        self.ys = np.dot(self.y.T, self.s)\n",
    "        self.hy = np.dot(self.h, self.y)\n",
    "        self.h += (1.0/self.ys) *(1 + np.dot(self.y.T, self.hy)/self.ys)*np.dot(self.s, self.s.T) \\\n",
    "        - (1.0/self.ys)*(np.dot(np.dot(self.s, self.y.T), self.h) + np.dot(self.hy, self.s.T))\n",
    "        return self.h\n",
    "    \n",
    "    def search_direction(self, iter_time):\n",
    "        self.grad, self.obj_values = self.first_order()\n",
    "        if iter_time == 0:\n",
    "            self.d = -1.0 * self.grad\n",
    "        else:\n",
    "            self.h = self.__approx_hessian()\n",
    "            self.d = -1.0 * np.dot(self.h, self.grad)\n",
    "        self.grad_hat, self.x_hat = self.grad.copy(), self.x.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bccf616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFP(Optimizer):\n",
    "    def __init__(self, model, eps) -> None:\n",
    "        super().__init__(model, eps)\n",
    "        self.h = self.__generate_approx_hessian()\n",
    "    \n",
    "    def __generate_approx_hessian(self):\n",
    "        return np.eye(self.m.dim)\n",
    "    \n",
    "    def __approx_hessian(self):\n",
    "        self.s, self.y = self.x - self.x_hat, self.grad - self.grad_hat\n",
    "        self.sy = np.dot(self.s.T, self.y)\n",
    "        self.hy = np.dot(self.h, self.y)\n",
    "        self.h += (1/self.sy) * np.dot(self.s, self.s.T) - np.dot(np.dot(self.hy, self.y.T), self.h) / (np.dot(self.y.T, self.hy))\n",
    "    \n",
    "    def search_direction(self, iter_time):\n",
    "        self.grad, self.obj_values = self.first_order()\n",
    "        if iter_time == 0:\n",
    "            self.d = -1.0 * self.grad\n",
    "        else:\n",
    "            self.h = self.__approx_hessian()\n",
    "            self.d = -1.0 * np.dot(self.h, self.grad)\n",
    "        self.grad_hat, self.x_hat = self.grad.copy(), self.x.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51152b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.1",
   "language": "python",
   "name": "tf2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
